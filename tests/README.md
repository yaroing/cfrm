# Tests de la Plateforme CFRM Humanitaire

Ce rÃ©pertoire contient tous les outils de test pour la plateforme de feedback communautaire humanitaire CFRM.

## ğŸ“ Structure des Fichiers

```
tests/
â”œâ”€â”€ README.md                    # Ce fichier
â”œâ”€â”€ run_tests.py                 # Script principal d'exÃ©cution
â”œâ”€â”€ test_automation.py           # Tests automatisÃ©s
â”œâ”€â”€ test_data.py                 # GÃ©nÃ©rateur de donnÃ©es de test
â”œâ”€â”€ test_scenarios.md            # ScÃ©narios de test dÃ©taillÃ©s
â”œâ”€â”€ kpi_metrics.py              # Calcul des KPI et mÃ©triques
â””â”€â”€ test_report_template.md     # ModÃ¨le de rapport de test
```

## ğŸš€ Utilisation Rapide

### ExÃ©cution Simple
```bash
cd tests
python run_tests.py
```

### ExÃ©cution avec Configuration
```bash
python run_tests.py --base-url http://localhost:8000 --verbose
```

## ğŸ“Š Types de Tests

### 1. Tests de RÃ©ception
- **SMS** : Messages multilingues, PSEA, urgences
- **Web** : Formulaires sÃ©curisÃ©s, donnÃ©es sensibles
- **Messageries** : WhatsApp, Telegram, groupes

### 2. Tests de Classification
- Classification automatique par catÃ©gorie
- DÃ©tection de la prioritÃ©
- Analyse du sentiment
- DÃ©tection PSEA/SEA

### 3. Tests de Performance
- Charge normale (100 msg/min)
- Charge Ã©levÃ©e (500 msg/min)
- Pic de charge (1000 msg/min)
- Temps de rÃ©ponse

### 4. Tests de SÃ©curitÃ©
- Protection contre les injections SQL
- Protection XSS
- Chiffrement des donnÃ©es PSEA
- ConformitÃ© RGPD

### 5. Tests d'IntÃ©gration
- APIs SMS (Twilio)
- APIs WhatsApp Business
- Service de traduction
- Notifications email

## ğŸ¯ KPI et MÃ©triques

### MÃ©triques Critiques
- **Taux de rÃ©ception** : â‰¥ 99.5%
- **DÃ©lai de traitement** : â‰¤ 15 minutes
- **PrÃ©cision classification** : â‰¥ 85%
- **Satisfaction utilisateur** : â‰¥ 8.0/10
- **Taux d'escalade PSEA** : 100%

### MÃ©triques par Canal
- **SMS** : Taux de succÃ¨s, temps de rÃ©ponse, satisfaction
- **Web** : Completion des formulaires, sÃ©curitÃ©
- **Messageries** : IntÃ©gration, mÃ©dias, groupes

## ğŸ”§ Configuration

### Variables d'Environnement
```bash
export CFRM_BASE_URL="http://localhost:8000"
export CFRM_TEST_MODE="development"
export CFRM_LOG_LEVEL="INFO"
```

### Configuration des Tests
```python
# Dans test_automation.py
tester = CFRMTestRunner(
    base_url="http://localhost:8000",
    timeout=30,
    retry_count=3
)
```

## ğŸ“ˆ GÃ©nÃ©ration de DonnÃ©es

### DonnÃ©es Humanitaires RÃ©alistes
Le gÃ©nÃ©rateur crÃ©e des donnÃ©es contextuelles :
- **Langues** : FranÃ§ais, Anglais, Arabe, Espagnol, Swahili, Amharique, Somali, Tigrinya
- **CatÃ©gories** : Information, Complaint, Request, PSEA, SEA, Feedback, Suggestion
- **Contextes** : Camps de rÃ©fugiÃ©s, dÃ©placement, urgence, rÃ©cupÃ©ration
- **Populations** : RÃ©fugiÃ©s, PDI, communautÃ©s d'accueil, groupes vulnÃ©rables

### Exemple d'Utilisation
```python
from test_data import TestDataGenerator

generator = TestDataGenerator()

# GÃ©nÃ©rer 100 messages SMS
sms_messages = generator.generate_sms_messages(100)

# GÃ©nÃ©rer 50 formulaires web
web_forms = generator.generate_web_forms(50)

# GÃ©nÃ©rer 75 messages de messagerie
messaging_messages = generator.generate_messaging_messages(75)
```

## ğŸ“‹ ScÃ©narios de Test

### ScÃ©narios SMS
- **SMS-001** : Demande d'aide alimentaire
- **SMS-002** : ProblÃ¨me eau potable urgent
- **SMS-003** : Message multilingue (arabe)
- **SMS-004** : Signalement PSEA
- **SMS-005** : Message de remerciement

### ScÃ©narios Web
- **WEB-001** : Formulaire complet valide
- **WEB-002** : Formulaire avec piÃ¨ce jointe
- **WEB-003** : Formulaire PSEA sÃ©curisÃ©
- **WEB-004** : Formulaire de remerciement
- **WEB-005** : Informations de vulnÃ©rabilitÃ©

### ScÃ©narios Messageries
- **MSG-001** : WhatsApp - Demande d'aide
- **MSG-002** : WhatsApp - Photo problÃ¨me
- **MSG-003** : Groupe - Coordination
- **MSG-004** : WhatsApp - Signalement PSEA
- **MSG-005** : Message arabe

## ğŸ“Š Rapports de Test

### Format JSON
```json
{
  "test_summary": {
    "test_date": "2024-01-15T10:30:00",
    "total_scenarios": 100,
    "scenarios_passed": 95,
    "scenarios_failed": 5,
    "success_rate": 95.0
  },
  "test_results": { ... },
  "kpi_results": { ... },
  "recommendations": [ ... ]
}
```

### Format Markdown
Le rapport est Ã©galement gÃ©nÃ©rÃ© en format Markdown pour une lecture facile.

## ğŸ” DÃ©pannage

### ProblÃ¨mes Courants

#### 1. Erreur de Connexion
```
ğŸ’¥ Erreur lors de l'exÃ©cution des tests: Connection refused
```
**Solution** : VÃ©rifier que le backend est dÃ©marrÃ© sur le port 8000

#### 2. Timeout des Tests
```
âš ï¸ Tests terminÃ©s avec des avertissements.
```
**Solution** : Augmenter le timeout dans la configuration

#### 3. Ã‰chec de Classification
```
âŒ Classification incorrecte de 2 messages
```
**Solution** : VÃ©rifier l'algorithme de classification et enrichir le dataset

### Logs de Debug
```bash
python run_tests.py --verbose --debug
```

## ğŸš€ IntÃ©gration CI/CD

### GitHub Actions
```yaml
name: CFRM Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: python tests/run_tests.py
```

### Jenkins Pipeline
```groovy
pipeline {
    agent any
    stages {
        stage('Test') {
            steps {
                sh 'python tests/run_tests.py'
            }
        }
    }
    post {
        always {
            publishHTML([
                allowMissing: false,
                alwaysLinkToLastBuild: true,
                keepAll: true,
                reportDir: 'tests',
                reportFiles: 'test_report_*.html',
                reportName: 'CFRM Test Report'
            ])
        }
    }
}
```

## ğŸ“š Documentation SupplÃ©mentaire

- [ScÃ©narios de Test DÃ©taillÃ©s](test_scenarios.md)
- [ModÃ¨le de Rapport](test_report_template.md)
- [Configuration des KPI](kpi_metrics.py)

## ğŸ¤ Contribution

Pour ajouter de nouveaux tests :

1. CrÃ©er un nouveau scÃ©nario dans `test_scenarios.md`
2. Ajouter les donnÃ©es de test dans `test_data.py`
3. ImplÃ©menter le test dans `test_automation.py`
4. Mettre Ã  jour les KPI si nÃ©cessaire
5. Tester et documenter

## ğŸ“ Support

Pour toute question sur les tests :
- CrÃ©er une issue sur GitHub
- Contacter l'Ã©quipe de dÃ©veloppement
- Consulter la documentation technique
